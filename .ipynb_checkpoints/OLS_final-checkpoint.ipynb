{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS no library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forrás: https://mubaris.com/posts/linear-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [-3.7,3.5,2.5,11.5,5.7]\n",
    "m0 = [1 for m in range(5)]\n",
    "m1 = [8,5,7,3,1]\n",
    "m2 = [5,4,3,2,6]\n",
    "X = [m0,m1,m2]\n",
    "\n",
    "\n",
    "def OLS(X,Y):\n",
    "    \n",
    "    B = [1 for m in X]\n",
    "    \n",
    "    \"\"\"\n",
    "    np_dot = np.dot függvény reprodukciója, vannak limitációi, de jelenlegi imputokkal működik.\n",
    "    Ha nő a változók száma változtatni kell az iteráción. Pl.: zip(X[0],X[1],X[2], X[3]) és \n",
    "    (B[0]*x1 + B[1]*x2 + B[2]*x3 + B[3]*x4)\n",
    "    \n",
    "    Mit csinál? - két mátrix szorzatát adja. Jelen esetben a béta vektort össeszorozzuk a hozzájuk tartozó\n",
    "    változók vektorával\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def np_dot(B,X):\n",
    "        J = []\n",
    "        b_enum = 0\n",
    "        if len(B) == len(X):\n",
    "            for x1,x2,x3 in zip(X[0],X[1],X[2]):\n",
    "                j = (B[0]*x1 + B[1]*x2 + B[2]*x3)\n",
    "                J.append(j)\n",
    "            return J\n",
    "        else:\n",
    "            return print(\"\"\"shapes not aligned: change zip(X[0],X[1],X[2]) \n",
    "            and/or (B[0]*x1 + B[1]*x2 + B[2]*x3)\"\"\")\n",
    "    \n",
    "    \"\"\"\n",
    "    cost_fun = MSE implementációja\n",
    "    Mit csinál? - Négyzetes hibák összegét adja meg.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def cost_fun(X,Y,B):\n",
    "        m = len(Y)\n",
    "        J = np_dot(B,X)\n",
    "        J = [x - y for (x, y) in zip(J, Y)]\n",
    "        J = [j**2 for j in J]\n",
    "        J = sum(J)/(2 * m)\n",
    "        return J \n",
    "        \n",
    "    \"\"\"\n",
    "     np_dot_grad = a gradient descenthez külön mátrix szorzás\n",
    "     Mit csinál? - np_dot fügvény eredményét szorozza meg újra a változók vektorával.\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    def np_dot_grad(loss,X):\n",
    "        J = []\n",
    "        for x in X:\n",
    "            j = (loss[0]*x[0] + loss[1]*x[1] + loss[2]*x[2] + loss[3]*x[3] + loss[4]*x[4])\n",
    "            J.append(j)\n",
    "        return J\n",
    "\n",
    "    \"\"\"\n",
    "    Gradient descent függvény használata a MSE minimalizálására\n",
    "    Mit csinál? - Iteratív folyamatban módosítja a béták értékét, és újraszámolja az MSE-t, hogy a \n",
    "    minimumához közeledjen. \n",
    "    \n",
    "    Az egyes lépések alfa méretűek. Mind az alfa, mind az iterációk száma módosítható. \n",
    "    \n",
    "    loss - hiba abszolút mérete az adott loopban\n",
    "    gradient - hiba relatív mérete (hiba*változó vektora)\n",
    "    B - a béták új értéke ami B- alfa*gradient (ha alfa nagyobb, gyorsabban közelít az optimumhoz, de túl nagy\n",
    "    alfa átugorhatja azt)\n",
    "    \n",
    "    \"\"\"\n",
    "    alpha = 0.01\n",
    "    iterations = 100000\n",
    "    def grad_descent(X, Y, B, alpha, iterations):\n",
    "        cost_history = [0] * iterations\n",
    "        m = len(Y)\n",
    "        for iteration in range(iterations):\n",
    "            H = np_dot(B,X)\n",
    "            loss = [h - y for (h, y) in zip(H, Y)]\n",
    "            gradient = np_dot_grad(loss,X)\n",
    "            gradient = [g/m for g in gradient]\n",
    "            alpha_grad = [alpha*g for g in gradient]\n",
    "            B = [b-a for (b, a) in zip(B, alpha_grad)]\n",
    "            #cost = cost_fun(X, Y, B)\n",
    "            #cost_history[iteration] = cost\n",
    "\n",
    "        return B\n",
    "    return grad_descent(X,Y,B,alpha,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.0526018808751, -1.6721003134794559, -2.281630094043472]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eredmény statsmodel-el**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Y = [-3.7,3.5,2.5,11.5,5.7]\n",
    "m1 = [8,5,7,3,1]\n",
    "m2 = [5,4,3,2,6]\n",
    "m0 = [1 for m in range(len(m1))]\n",
    "X = [m0,m1,m2]\n",
    "\n",
    "d = {'col1': m1, 'col2': m2, 'col3': m0, 'col4': Y}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    21.052602\n",
       "col1         -1.672100\n",
       "col2         -2.281630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = smf.ols(data=df, formula= 'col4 ~ col1 + col2')\n",
    "res = model.fit()\n",
    "res.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
